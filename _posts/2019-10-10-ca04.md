---
layout: post
title: "컴퓨터 구조 2 - 03"
tags: [CA]
comments: true
---

## Block size

블록 사이즈를 늘리면 miss rate가 감소한다.

하지만 사이즈를 너무 늘리면 캐시 안의 블록 수가 줄어드므로 miss rate와 miss penalty가 커진다.

```cs
Miss penalty = block fetch time + cache load time;
Block fetch time = latency to the first word + transfer time for the rest of the blcok;
```
Transfer time은 블록 사이즈에 비례하므로 블록 사이즈를 늘리면 miss penalty 역시 증가한다.

---------------------------------------------

## Reducing Miss Penalty

Early restart
: Resume execution as soon as the requested word of the block is returned

REquested word first
: Organize the memory so requested word is transfeered first

Early restart는 전체 블록을 기다리지 않고 요청한 블록의 word가 돌아오자마자 실행을 재개한다.

주로 sequential한 instruction accesses을 위해 많은 프로세서들이 이를 사용한다.

하지만 data caches에서는 덜 효과적인데, 블록에서 요청되는 words가 덜 예측적(less predictable)이고, 전송이 완료되기 전에 프로세서가 다른 캐시 블록의 word를 요청할 가능성이 높기 때문이다.

requested word first는 critical word first로도 불리며, early restart보다 약간 더 빠르지만 early restart와 같은 한계가 있다.

-----------------------------------

## Handling Cache Misses

Cache miss
: A request for data from the cache that cannot be filled because the data is not present in the cache

#### Instruction cache miss

1. Send PC -4 to the memory

2. Instruct main memory to perform a read/wait for the memory to complete its access

3. Write the cache entry(Update data/tag/v-bit)

4. Restart the instruction execution at the first step

프로그램 카운터는 실행의 첫번째 사이클에 증가하기 때문에 -4를 한다.

Data cache miss
: Stall the processor until the memory responds with the data.

----------------------------------------------------

## Handling Writes

write miss는 cpu가 캐시에 write한 데이터가 메모리와 다를 때 일어난다.

**Write-through policy** 는 항상 데이터를 메모리와 캐시 양쪽에 적는다.

즉, 메인 메모리와 캐시를 일관되게 유지한다.

### on write-miss
1. Fetch the block containing the word
2. overwrite the word into the cache block
3. Also write the word to main memory

### on write-hit
1. overwrite the word into the cache block
2. Also write the word to main memory

write-through는 성능이 저하하는 문제를 가지고 있다.

모든 write가 data를 메모리에 쓰이게 하여 머신을 느리게 한다.

SPEC2000 integer benchmarks를 보면

* 10% of the instructions are stores
* cache miss = 10% 일때 CPI = 1.0+100*0.1 = 11
* 성능을 factor of 10으로 줄인다.

성능 저하 문제를 해결하기 위해 wirte buffer가 쓰인다.

**Write Buffer** 는 메모리에 쓰이기 위해 기다리는 동안 데이터를 hold하는 큐이다.

데이터를 캐시와 write buffer에 쓰고 프로세서는 실행을 계속한다.

**Write back** 은 캐시에 있는 블록의 값만 갱신하여 쓰기를 수행하다가 그 블록이 교체될 때 메모리 계층구조의 하위 계층에 갱신된 블록을 쓴다.

더 좋은 성능을 가지지만 구현하기가 어렵다.

-------------------------------------------------------

## Split caches

Split caches
: A scheme in which a level of the memory hierachy is composed of two independent caches that operate in parallel with each other, with one handling instructions and one handling data.

### Miss rates for Intrinsity FastMATH
* Split cache: 3.24%
* Combined cache: 3.18%

combined cache는 더 높은 더 높은 hit rate를 가지고 있다.

하지만 대역폭을 높이기 위해 현대의 프로세서 대부분이 instruction cache와 data cache를 나누어서 사용한다.

split cache의 hit rate가 조금 더 나쁘지만 캐시 대역폭을 두배로 늘림으로 이를 극복할 수 있다.

큰 대역폭은 miss penalty를 줄여 더 큰 블록 사이즈를 사용할 수 있게 한다.


----------------------

Spatial locality
: 특정 기억 장소들에 대해 참조가 집중적으로 이루어지는 경향. 프로그램 실행 시 접근하는 메모리 영역은 이미 접근이 이루어진 영역 근처일 확률이 높다.

Spatial locality의 이점을 활용하기 위해, cache는 반드시 1 word보다 큰 블록 사이즈를 가져야 한다.

더 큰 블록은 miss rate를 낮추고 tag storage를 줄여 cache의 효율을 높인다.

블록 사이즈를 늘리면 miss rate는 줄지만 대신 miss penalty 또한 커져 성능 하락으로 이어진다.

성능 하락을 피하기 위해 메인 메모리의 대역폭을 늘려 cache block을 효율적으로 전송해야 한다.

DRAM 대역폭을 늘리기 위한 방법으로 메모리를 wider and interleaving 으로 만드는 것이 있다.

메모리 인터리빙
: 메모리 접근 시간을 최소화하기 위해 여러 모듈로 나눈 메모리에 동시 접근하는 기법
